## Real-Time Customer Sentiment Stream (Hadoop/Spark/Kafka)

### Project Overview

This project implements a highly resilient, end-to-end Big Data pipeline for real-time sentiment analysis of customer reviews. It demonstrates core skills in distributed computing, data streaming, and cross-platform container orchestration.

### Key Features:

Real-time Ingestion: Leverages Kafka for high-throughput, fault-tolerant data streaming.

Distributed Processing: Utilizes Apache Spark Streaming on a Hadoop YARN cluster for scalable sentiment analysis.

Persistent Storage: Stores processed data in HDFS for archival 

Containerized Environment: Orchestrates all services using Docker and Docker Compose for easy deployment and isolation.

### Technologies Used:

Apache Spark (2.2.0, DStreams)

Apache Kafka (0.8 API)

Apache Hadoop (2.7.2, YARN/HDFS)

Python (Producer, Sentiment Analysis)

Docker / Docker Compose

## Explication du Pipeline (Sch√©ma)

Votre architecture est divis√©e en trois phases principales, toutes orchestr√©es par Docker :

| Phase | Description | Technologies |
|-------|-------------|--------------|
| **1. Ingestion & R√©ception (V√©locit√©)** | Votre conteneur Producer (Python) lit le fichier `data.ndjson` depuis votre PC local (via un volume Docker) et publie chaque avis, ligne par ligne, dans le Topic Kafka (`client_comments`). | Python, Docker, Kafka |
| **2. Traitement & Analyse** | Spark Streaming (sur YARN) agit comme un consommateur. Il lit le flux Kafka, utilise une UDF (votre dictionnaire) pour classer le sentiment, et agr√®ge les r√©sultats toutes les 5 secondes. | Spark Streaming, YARN |
| **3. Persistance ** | Spark √©crit les r√©sultats dans deux syst√®mes diff√©rents : **Archivage (Volume)** : Les avis bruts et analys√©s sont stock√©s dans des dossiers horodat√©s sur HDFS. | HDFS |



### üöÄ Guide de D√©marrage (Pour un Nouvel Utilisateur)

Ce guide fournit la s√©quence de commandes compl√®te pour lancer le pipeline depuis z√©ro.

### Pr√©-requis

Git et Docker Desktop (Doit √™tre en cours d'ex√©cution).

Le dossier du projet contient tous les fichiers (y compris docker-compose.yml, sentiment_analysis.py, et votre fichier de donn√©es data.ndjson).

## Phase 1: D√©ploiement et D√©marrage du Cluster Hadoop

Le cluster Hadoop (Master/Slaves) est lanc√© manuellement pour cr√©er le r√©seau de base (hadoop) n√©cessaire √† tous les autres services.

# Entrer dans le dossier du projet
```bash
cd votre-dossier-de-projet
```

# 1. T√©l√©charger l'image de base Hadoop/Spark
```bash
docker pull liliasfaxi/spark-hadoop:hv-2.7.2
```

# 2. Cr√©er le r√©seau interne 'hadoop'
```bash
docker network create --driver=bridge hadoop
```

# 3. Lancer le Master Hadoop (NameNode/YARN)
```bash
docker run -itd --net=hadoop -p 9870:9870 -p 8088:8088 -p 7077:7077 -p 16010:16010 --name hadoop-master --hostname hadoop-master liliasfaxi/spark-hadoop:hv-2.7.2
```

# 4. Lancer les deux Slaves Hadoop (DataNodes/NodeManagers)
```bash
docker run -itd -p 8040:8042 --net=hadoop --name hadoop-slave1 --hostname hadoop-slave1 liliasfaxi/spark-hadoop:hv-2.7.2
docker run -itd -p 8041:8042 --net=hadoop --name hadoop-slave2 --hostname hadoop-slave2 liliasfaxi/spark-hadoop:hv-2.7.2
```

## Phase 2: Activation des Services Hadoop/YARN

Les services internes sont souvent bloqu√©s ou arr√™t√©s au d√©marrage du conteneur. Nous devons les d√©marrer et d√©bloquer YARN.

# 1. Entrer dans le Master et ex√©cuter le script de d√©marrage
```bash
docker exec -it hadoop-master bash -c "./start-hadoop.sh"
```

# 2. Forcer la d√©sactivation du mode s√©curis√© HDFS (Safe Mode)
# C'est crucial pour d√©bloquer YARN et permettre √† Spark de sauvegarder les donn√©es.
```bash
docker exec -it hadoop-master hdfs dfsadmin -safemode leave
```

## Phase 3: D√©ploiement de la Pipeline de Flux (Kafka/Producer)

Nous utilisons docker-compose pour lancer les services de streaming et monter le fichier de donn√©es local.

# 1. Construire l'image du Producteur et d√©marrer Kafka/Zookeeper/Producer
# Le Producer lira le fichier data.ndjson de votre machine h√¥te gr√¢ce √† la section 'volumes' du docker-compose.yml.
```bash
docker-compose up -d --build
```

## Phase 4: Lancement du Job Spark Streaming

L'infrastructure est stable et le Producteur envoie des donn√©es. Nous lan√ßons l'analyse.

# 1. Copier le script PySpark (sentiment_analysis.py) dans le Master
```bash
docker cp sentiment_analysis.py hadoop-master:/opt/
```

# 2. Lancer le Job Spark sur YARN
# NOTE: La commande inclut la compatibilit√© Python 3 et le package Kafka 0.8 n√©cessaire.
```bash
docker exec -it hadoop-master bash -c "PYSPARK_PYTHON=python3 spark-submit --packages org.apache.spark:spark-streaming-kafka-0-8-assembly_2.11:2.2.0 --master yarn --deploy-mode client /opt/sentiment_analysis.py"
```

## ‚úÖ V√©rification et Sortie des Donn√©es

1. V√©rification de la Persistance HDFS

Pour v√©rifier que le job √©crit les donn√©es :

# Entrer dans le Master container
```bash
docker exec -it hadoop-master bash
```
# Lister le dossier des comptages (Batch et Comptages)
```bash
hdfs dfs -ls /user/root/testProject/sentiment_counts_v2

# Pour lire le contenu d'un fichier de comptage (ex: POSITIF/NEGATIF)
# REMPLACER les placeholders XXXXXX par les vrais noms de fichiers
# hdfs dfs -cat /user/root/testProject/sentiment_counts_v2/batch-XXXXXX/part-XXXXXX.json
```

2. Surveillance

Statut YARN (Applications) : http://localhost:8088

üõë Arr√™t de la Pipeline

Pour arr√™ter tous les services proprement :

# 1. Arr√™ter le Job Spark (Ctrl+C dans le terminal o√π il tourne)
# 2. Arr√™ter les services Kafka/Zookeeper/Producer
```bash
docker-compose down
```
# 3. Arr√™ter les conteneurs Hadoop Master et Slaves
```bash
docker stop hadoop-master hadoop-slave1 hadoop-slave2
docker rm hadoop-master hadoop-slave1 hadoop-slave2
```
# 4. Supprimer le r√©seau Docker
```bash
docker network rm hadoop
```
